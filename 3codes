# FIRST ALGORITHM : to create the R2 bootstrap samples

import numpy as np
import os
import readcorr as r #library I created to generate the correlators bootstrap samples
import analysisbin as ab #library I created to perpetuate the bootstrap analysis on the ratios
import bootstrap as b #average and std for bootstrap samples
import CovM #library to compute the covariance matrix using Cholesky decomposition (unused)


def array_print(tab):# to print 1D array in terminal
    print('[' + str(tab[0]))
    for k in range(1, len(tab)-1):
        print(',' + str(tab[k]))
    print(',' + str(tab[len(tab)-1]) + ']')
    
def matrix_print(tab):# to print 2D array in terminal
    print('[')
    for l in range(tab.shape[0]):
        array_print(tab[l,:])
    print(']')


pseudo = np.loadtxt('pseudo_clean').astype(int) #pseudo random number generator

dtsum = input('Enter the dtsum value :') #dtsum is the total source-sink separation. Here we compute the R2 bootstrap sample of one sub data set, for all D momentum norm, but for one dtsum

name_list= ['mom1_avg123-4', 'mom2_avg123-4', 'mom3_avg123-4', 'mom4_avg123-4'] #corresponding to the 4 momentum norm values for one sub sub data set
#Note that the momentum norm called "i" (i = 1,2,3 or 4) corresponds to lattice momentum norm sqrt(i)*2 pi / L (with L the lattice spatial size)

mom_list= [["+1+0+0_+0+0+0_-1+0+0", "-1+0+0_+0+0+0_+1+0+0","+0+1+0_+0+0+0_+0-1+0", "+0-1+0_+0+0+0_+0+1+0", "+0+0+1_+0+0+0_+0+0-1", "+0+0-1_+0+0+0_+0+0+1"], ["+1+0+1_+0+0+0_-1+0-1", "-1+0+1_+0+0+0_+1+0-1", "+1+0-1_+0+0+0_-1+0+1","-1+0-1_+0+0+0_+1+0+1", "+1+1+0_+0+0+0_-1-1+0" , "-1+1+0_+0+0+0_+1-1+0", "+1-1+0_+0+0+0_-1+1+0" , "-1-1+0_+0+0+0_+1+1+0" ,  "+0+1+1_+0+0+0_+0-1-1", "+0-1+1_+0+0+0_+0+1-1", "+0-1-1_+0+0+0_+0+1+1", "+0+1-1_+0+0+0_+0-1+1"] , ["+1+1+1_+0+0+0_-1-1-1",  "+1+1-1_+0+0+0_-1-1+1", "+1-1+1_+0+0+0_-1+1-1", "-1+1+1_+0+0+0_+1-1-1", "+1-1-1_+0+0+0_-1+1+1", "-1-1+1_+0+0+0_+1+1-1",  "-1+1-1_+0+0+0_+1-1+1", "-1-1-1_+0+0+0_+1+1+1"], [ "+2+0+0_+0+0+0_-2+0+0", "-2+0+0_+0+0+0_+2+0+0","+0+2+0_+0+0+0_+0-2+0", "+0-2+0_+0+0+0_+0+2+0", "+0+0+2_+0+0+0_+0+0-2", "+0+0-2_+0+0+0_+0+0+2"]]


tensor = ['T14', 'T24', 'T34']

mass_list = ['0.44037', '0.55046', '0.68808'] #in the case of the sub data set (beta = 4.17, mq = 0.0070), here are the bottom quark masses

mondico = dict() # I create this dictionary to store the bootstrap samples of the correlators for different momenta and bottom mass (which will be the key of the dictionnary in the format 'mass_momentum')

os.chdir('/home/mfaur/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/tsrc00/2pt/DD') #I navigate in the workstation to get to the folder where the D meson correlators are stored


file = 'msn_2pt_pp_m0.44037_0.01200_theta+0.0000+0.0000+0.0000_+0.0000+0.0000+0.0000_mom+0+0+0_smr10_{id}'
end = r.generate_end_short()
DD_0_re, DD_0_im = r.oneformat(file, end, dtsum+1)
DD_0 = DD_0_re + 1j*DD_0_im
# these four command lines allow me to extract the bootstrap samples of the D decay two point correlator for one momentum vector (here +0+0+0)



os.chdir('/home/mfaur/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/tsrc00/3pt/dtsum{dir1}/V4'.format(dir1 = dtsum))
 
for k in range(len(mass_list)):
# For each bottom quark mass we extract the D to B meson decay three point correlator bootstrap samples, the D momentum is 0 here
    file = 'msn_3pt_p_p_v4_m0.01200_{mass}_0.44037_theta+0.0000+0.0000+0.0000_+0.0000+0.0000+0.0000_+0.0000+0.0000+0.0000_mom+0+0+0_+0+0+0_+0+0+0'.format(mass= mass_list[k])
    file = file +'_smr11_{id}'
    D2B_0_re, D2B_0_im = r.oneformat_3pt_thin(file, end, dtsum)
    D2B_0 = D2B_0_re + 1j*D2B_0_im
    mondico['{n}_0'.format(n = mass_list[k][2])] = D2B_0
    


for i in range (len(mom_list)):
# For each non zero D momentum and bottom quark mass we extract the D decay two point correlator bootstrap samples and the D to B decay three point correlator bootstrap samples.
    DD_p = 0
    for k in range(len(mass_list)):
        mondico['{n}'.format(n = mass_list[k][2])] = 0
    
    for t in tensor:
        for mom_curr in mom_list[i]:
            if mom_curr[int(t[1])*2-1] != '0': #if we have T12, we enter the if loop iff the current momentum 'mom_curr' has a non zero y coordinate


                
                os.chdir('/home/mfaur/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/tsrc00/2pt/DD')
                file = 'msn_2pt_pp_m0.44037_0.01200_theta+0.0000+0.0000+0.0000_+0.0000+0.0000+0.0000_mom{mom_in}'.format(mom_in = mom_curr[:6])
                file = file + '_smr10_{id}'
                DD_p_re, DD_p_im = r.oneformat(file, end, dtsum +1)
                DD_p = DD_p_re + 1j*DD_p_im + DD_p
                

                
                for k in range(len(mass_list)):
                    os.chdir('/home/mfaur/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/tsrc00/3pt/dtsum{dir1}/{dir2}'.format(dir1 = dtsum, dir2 = t))
                    file = 'msn_3pt_p_p_{matrix_low}_m0.01200_{mass}_0.44037_theta+0.0000+0.0000+0.0000_+0.0000+0.0000+0.0000_+0.0000+0.0000+0.0000_mom{mom_in}'.format(matrix_low = t.lower(), mom_in = mom_curr, mass = mass_list[k])
                    file = file + '_smr11_{id}'
                    D2B_p_re, D2B_p_im = r.oneformat_3pt_thin(file, end, dtsum)
                   
                    if mom_curr[int(t[1])*2-2] == '+': #check the sign
                        mondico['{n}'.format(n = mass_list[k][2])] = D2B_p_re + 1j*D2B_p_im + mondico['{n}'.format(n = mass_list[k][2])]
                    else :
                        mondico['{n}'.format(n = mass_list[k][2])] = -D2B_p_re + 1j*D2B_p_im + mondico['{n}'.format(n = mass_list[k][2])]
                    



    DD_p = DD_p/(len(mom_list[i])*len(tensor))
#we finally average over the different momenta sharing the same norm, and the different tensor terms equivalent under Lorentz covariance


    for l in range(len(mass_list)):
    #for each bottom mass, we compute the ratio R2
        current = mondico['{n}'.format(n = mass_list[l][2])]
        current0 = mondico['{n}_0'.format(n = mass_list[l][2])]
        current = current/(len(mom_list[i])*len(tensor))

        
        R = ab.R(DD_p, current0, current, DD_0, dtsum +1, pseudo, 25)
        R = R[:,0] #the two other column are not interesting (complex sigma, wrongly computed, and biais)

        R_c, sigmaR, sigmaI = ab.Rchi2_3(DD_p, current0, current, DD_0, dtsum +1, pseudo, 25)
        R_c = np.array(R_c, dtype=complex)

        os.chdir('/xwork18/scqcd/mfaur/NewSigma/R/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/dtsum{dir1}'.format(dir1 = dtsum))

        try :
            os.mkdir('{dir2}'.format(dir2 = name_list[i]))
            #I create a folder to store the R2 bootstrap samples for the inputted dtsum
        except:
            print('already exists - {dir2}'.format(dir2 = name_list[i]))

        os.chdir('/xwork18/scqcd/mfaur/NewSigma/R/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/dtsum{dir1}/{dir2}'.format(dir1 = dtsum, dir2 = name_list[i]))

        print("That's R/sigma.real-imag for mb={n}, from {dir1} \n".format(dir1 = name_list[i], n = mass_list[l]))
        array_print(R)
        array_print(sigmaR)
        array_print(sigmaI)


        np.savetxt('R_{n}'.format(n = mass_list[l][2]), R)


        M5 = CovM.CovM_simple(R_c.real, dtsum +1, 5000)
        if not(CovM.isPD(M5)):
            M5 = CovM.nearestPD(M5)
        M5, N5_cho = CovM.inverse(M5, dtsum)
        #I compute here the covariance matrix of the R2 bootstrap samples real part
        # I wanted to use it in fit functions, but in the end I just used standard errors.

        print('True if the matrix is correctly inversed using Cholesky decomposition - M : ', np.allclose(np.dot(N5_cho, M5), np.eye(dtsum+1)))


        MI5 = CovM.CovM_simple(R_c.imag, dtsum +1, 5000)
        if not(CovM.isPD(MI5)):
            MI5 = CovM.nearestPD(MI5)
        MI5, NI5_cho = CovM.inverse(MI5, dtsum)
        #I compute here the covariance matrix of the R2 bootstrap samples imaginary part
        # I wanted to use it in fit functions, but in the end I just used standard errors.
        
        print('True if the matrix is correctly inversed using Cholesky decomposition - MI : ', np.allclose(np.dot(NI5_cho, MI5), np.eye(dtsum+1)))

        try :
            os.mkdir('chi2_{n}'.format(n=mass_list[l][2]))
        except :
            print('folder already exists - chi2{n}'.format(n=mass_list[l][2]))


        os.chdir('/xwork18/scqcd/mfaur/NewSigma/R/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/dtsum{dir1}/{dir2}/chi2_{n}'.format(dir1 = dtsum, dir2 = name_list[i], n = mass_list[l][2]))

        #Finally, I save the 5000 R2 bootstrap samples generated for a given bottom mass and momentum norm for the sub data set (beta = 4.17, mq=0.0070)
        #Thanks to the loops over the bottom masses and the momentum norms, I generate with this algorithm all the R2 bootstrap sample for one sub data set and one dtsum.

        np.savetxt('sample_sigma', sigmaR)

        np.savetxt('sample_cov_inv', N5_cho.flatten())

        np.savetxt('sample_sigma_im', sigmaI)

        np.savetxt('sample_cov_inv_im', NI5_cho.flatten())

        np.savetxt('samples_total', R_c.real)

        np.savetxt('samples_total_im', R_c.imag)

        for k in range(5000):
            file = 'sample_{id}'
            M = np.array((list(R_c.real[:,k]), list(R_c.imag[:,k])))
            np.savetxt(file.format(id=k), M.transpose())

        os.chdir('/xwork18/scqcd/mfaur/NewSigma/R/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400')

-----------------------------------------------------------------------------------------------------------------------------------------------------------------
# SECOND ALGORITHM : to create the dtsum mixed ratio samples

import numpy as np
import os
import readcorr as r
import analysisbin as ab
import bootstrap as b
import CovM

def array_print(tab):#1D array
    print('[' + str(tab[0]))
    for k in range(1, len(tab)-1):
        print(',' + str(tab[k]))
    print(',' + str(tab[len(tab)-1]) + '],')
    
def matrix_print(tab):#1D array
    print('[')
    for l in range(tab.shape[0]):
        array_print(tab[l,:])
    print(']')

mass = [4,5,6] #keys referring to the masses 0.44037, 0.55046, 0.68808

tab_cut = input('tuples of slicing values to cut the samples on, for the real part // dtsum :')
tab_cut_im = input('tuples of slicing values to cut the samples on, for the imaginary part // dtsum :')
#example [(1, -1), (1, -1), (1, -1), (1, -1)]
#I don't use this tab_cut in my final analysis


name = input('Name of the file to put the results in (mix) :')


dtsum = np.array([12, 16, 22, 26]) # We will glue together for each bootstrap sample numbers the corresponding 4 bootstrap samples with these 4 different dtsums


os.chdir('/xwork18/scqcd/mfaur/NewSigma/R/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/mix')

try:
    os.mkdir(name)
    
except:
    print('{mom} already exists'.format(mom = name))



for m in mass:
    os.chdir('/xwork18/scqcd/mfaur/NewSigma/R/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/mix/{mom}'.format(mom=name))
    try:
        os.mkdir('chi2_{n}'.format(n=m))
    except:
        print('chi2_{n} already exists'.format(n=m))



    new_R = []
    new_R_im = []

#We run through the bootstrap samples to assemble the different dtsum ratio samples with the same bootstrap index into one file, and to compute the standard deviation to the new 5000 samples

    for k in range(5000):
        new_sample = []
        new_sample_im = []
        sigma = []
        sigma_im = []
        for i in range(len(dtsum)):
            os.chdir('/xwork18/scqcd/mfaur/NewSigma/R/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/dtsum{dt_in}/{mom}/chi2_{n}'.format(dt_in = dtsum[i], mom = name, n = m))
            if k == 0 : 
                print(os.getcwd())
                file= 'sample_sigma'
                sample = np.loadtxt(file)
                re = list(sample[tab_cut[i][0]:tab_cut[i][1]])
                sigma = sigma + re
                file= 'sample_sigma_im'
                sample = np.loadtxt(file)
                im = list(sample[tab_cut_im[i][0]:tab_cut_im[i][1]])
                sigma_im = sigma_im + im
            file = 'sample_{num}'
            sample = np.loadtxt(file.format(num = k))
            re = list(sample[tab_cut[i][0]:tab_cut[i][1],0])
            im = list(sample[tab_cut_im[i][0]:tab_cut_im[i][1],1])
            new_sample = new_sample + re
            new_sample_im = new_sample_im + im


        os.chdir('/xwork18/scqcd/mfaur/NewSigma/R/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/mix/{mom}/chi2_{n}'.format(mom = name, n = m))
        np.savetxt('sample_{num}'.format(num=k), np.array(new_sample))
        np.savetxt('sample_im_{num}'.format(num=k), np.array(new_sample_im))
        new_R.append(np.array(new_sample)) # to get 5000*dt tabs
        new_R_im.append(np.array(new_sample_im))
        if k == 0:
            dt = len(sigma)
            dt_im = len(sigma_im)
            np.savetxt('sample_sigma', np.array(sigma))
            np.savetxt('sample_sigma_im', np.array(sigma_im))


    new_R = np.array(new_R)
    new_R_im = np.array(new_R_im)
    print(new_R.shape, new_R_im.shape)

#We compute the covariance matrix to the bootstrap samples if we want to use it in the chi2 minimization algorithms
    M = CovM.CovM_simple(new_R, dt, 5000)
    if not(CovM.isPD(M)):
        M2 = CovM.nearestPD(M)
    M3, N_cho = CovM.inverse(M2, dtsum = dt-1)
    print('True if the matrix is correctly inversed using Cholesky decomposition - M: ', np.allclose(np.dot(N_cho, M3), np.eye(dt)))

    MI = CovM.CovM_simple(new_R_im, dt_im, 5000)
    if not(CovM.isPD(MI)):
        MI2 = CovM.nearestPD(MI)
    MI3, NI_cho = CovM.inverse(MI2, dtsum = dt_im-1)
    print('True if the matrix is correctly inversed using Cholesky decomposition - MI : ', np.allclose(np.dot(NI_cho, MI3), np.eye(dt_im)))

    os.chdir('/xwork18/scqcd/mfaur/NewSigma/R/SymDW_sHtTanh_b2.0_smr3_32x64x12_b4.17_M1.00_mud0.0120_ms0.0400/mix/{mom}/chi2_{n}'.format(mom = name, n=m))

#We save the new bootstrap samples for the sub data set in question. They no longer depend on dtsum

    np.savetxt('sample_cov', M3.flatten())

    np.savetxt('sample_cov_inv', N_cho.flatten())

    np.savetxt('samples_total', new_R)
    
    np.savetxt('samples_total_im', new_R_im)
    
    np.savetxt('sample_cov_im', MI3.flatten())

    np.savetxt('sample_cov_inv_im', NI_cho.flatten())


----------------------------------------------------------------------------------------------------------------------------------------------------------------

#THIRD ALGORITHM : Fitting the bootstrap sample of one sub sub data set to get the R2 groundstate contribution



import os
import numpy as np
from tqdm import tqdm
from scipy.optimize import curve_fit

#I input all this information here to be able to navigate in my storage files
file = input('Data set name : ')
file_ED = input('name of the file where we find the energy for D meson (mom1) : ')
file_EB = input('name of the file where we find the energy for B meson  : ')
file_hp = input('name of the file where we find h+(w=1) : ')
mass_in = int(input('mass name : '))
L = int(input('L value : '))
dtsum1 = input('dtsum1 : ')
dtsum2 = input('dtsum2 : ')
dtsum3 = input('dtsum3 : ')
dtsum4 = input('dtsum4 : ')

dtsums = [int(dtsum1), int(dtsum2), int(dtsum3), int(dtsum4)]
cut = int(input('cut : '))
#In the case of (beta = 4.17, mq = 0.0070), we cut the time range by removing the first and last 6 points for this data set : cut = 6
# For other data set, we remove the same quantity of points, weighted by the lattice spacing

os.system('sshfs mfaur@scbc2fe.kek.jp:/xwork18/scqcd/mfaur/NewSigma/R/{dataset}/mix /Users/melissafaur/Desktop/mom1'.format(dataset = file))

os.chdir('/Users/melissafaur/Desktop/mom1/Bootstrap')


#In the sub sub data set in question, for a given momentum (here norm "1") we upload in the code the energy values of the D and B meson from files at disposal in the work station, created by T. Kaneko

tab = np.loadtxt(file_ED)

deltaED = tab[1:,9]-tab[1:,7]

tab = np.loadtxt(file_EB)

deltaEB = tab[1:,9]-tab[1:,7]

tab = np.loadtxt(file_hp)

hptab = tab[1:, -1]
MBtab = tab[1:, 3]
MDtab = tab[1:, 4]
Mpitab = tab[1:,1]
MKtab = tab[1:,2]

os.chdir('/Users/melissafaur/Desktop/mom1/mom1_avg123-4/chi2_{mass}'.format(mass=mass_in))


tab = np.loadtxt('samples_total')
sig = np.loadtxt('sample_sigma')


time_mask = list(np.arange(dtsums[0]+1)[cut: -cut]) + list(np.arange(dtsums[1]+1)[cut: -cut] + dtsums[0]+1) + list(np.arange(dtsums[2]+1)[cut: -cut] + dtsums[0]+1 + dtsums[1]+1) + list(np.arange(dtsums[3]+1)[cut: -cut] +dtsums[0]+1 +  dtsums[1]+1 +  dtsums[2]+1 )

newt = []
newsig = []
for k in range(5000):
    newt.append(list(tab[k,time_mask]))
newsig = sig[time_mask]
tab.shape

newt = np.array(newt)
newsig = np.array(newsig)


hT = []

wtab = []

# We fit all the bootstrap samples for the given sub sub data set and momentum norm "1" with the same function, while carefully considering the right bootstrap energy values
    
for k in tqdm(range(5000)):
    E = deltaED[k]
    Ep = deltaEB[k]
    MB = MBtab[k]
    MD = MDtab[k]
    hp = hptab[k]
    mom = 2*np.pi/L
    q2 = (MB - np.sqrt(MD**2 + mom**2))**2 - mom**2
    w = (MB**2 + MD**2 - q2)/(2*MD*MB) #book HQphysics page 66
    @np.vectorize
    def fit(x, R,A,B):
        if x in list(np.arange(dtsums[0]+1)[cut: -cut]):
            return R + A*np.exp(-E*x)+B*np.exp(-Ep*(dtsums[0]-x))
        elif x in list(np.arange(dtsums[1]+1)[cut: -cut] + dtsums[0]+1):
            return R + A*np.exp(-E*(x-(dtsums[0]+1)))+B*np.exp(-Ep*(dtsums[1]-x + dtsums[0]+1))
        elif x in list(np.arange(dtsums[2]+1)[cut: -cut] + dtsums[0]+1 + dtsums[1]+1):
            return R + A*np.exp(-Ep*(x-(dtsums[0]+1 + dtsums[1]+1)))+B*np.exp(-Ep*(dtsums[2]-x + dtsums[0]+1 + dtsums[1]+1))
        else:
            return R + A*np.exp(-E*(x-(dtsums[0]+1 + dtsums[1]+1 + dtsums[2]+1)))+B*np.exp(-Ep*(dtsums[3]-x+dtsums[0]+1 + dtsums[1]+1 + dtsums[2]+1))
    var, Cov = curve_fit(fit, time_mask, newt[k,:],  p0 = [0,0,0], sigma = newsig, absolute_sigma = True, maxfev = 5000)
    hT.append(-var[0]*L*MD*hp/np.pi) #we multiply the groundstate R2 (var[0]) by the appropriate coefficient to obtain a tensor form factor value
    wtab.append(w)

print('hT avg value for mom1 :', np.array(hT).mean(), np.array(hT).std())
    
os.chdir('/Users/melissafaur/Desktop/Data_analysis/Results')

# we save the obtained tensor form factor bootstrap samples in the 'Results' file
np.savetxt('{name}-{mass}-{mom}'.format(name=file, mass=mass_in, mom=1), (hT, wtab, Mpitab, np.sqrt(2*MKtab**2 - Mpitab**2)))


#We repeat the procedure for momentum norm "2"

hT = []

wtab = []

file_ED = input('name of the file where we find the energy for D meson (mom2) : ')

os.chdir('/Users/melissafaur/Desktop/mom1/Bootstrap')

tab = np.loadtxt(file_ED)
deltaED = tab[1:,9]-tab[1:,7]

os.chdir('/Users/melissafaur/Desktop/mom1/mom2_avg123-4/chi2_{mass}'.format(mass=mass_in))


tab = np.loadtxt('samples_total')
sig = np.loadtxt('sample_sigma')

newt = []
newsig = []
for k in range(5000):
    newt.append(list(tab[k,time_mask]))
newsig = sig[time_mask]
tab.shape

newt = np.array(newt)
newsig = np.array(newsig)

for k in tqdm(range(5000)):
    E = deltaED[k]
    Ep = deltaEB[k]
    MB = MBtab[k]
    MD = MDtab[k]
    hp = hptab[k]
    mom = np.sqrt(2)*2*np.pi/L
    q2 = (MB - np.sqrt(MD**2 + mom**2))**2 - mom**2
    w = (MB**2 + MD**2 - q2)/(2*MD*MB) #book HQphysics page 66
    @np.vectorize
    def fit(x, R,A,B):
        if x in list(np.arange(dtsums[0]+1)[cut: -cut]):
            return R + A*np.exp(-E*x)+B*np.exp(-Ep*(dtsums[0]-x))
        elif x in list(np.arange(dtsums[1]+1)[cut: -cut] + dtsums[0]+1):
            return R + A*np.exp(-E*(x-(dtsums[0]+1)))+B*np.exp(-Ep*(dtsums[1]-x + dtsums[0]+1))
        elif x in list(np.arange(dtsums[2]+1)[cut: -cut] + dtsums[0]+1 + dtsums[1]+1):
            return R + A*np.exp(-Ep*(x-(dtsums[0]+1 + dtsums[1]+1)))+B*np.exp(-Ep*(dtsums[2]-x + dtsums[0]+1 + dtsums[1]+1))
        else:
            return R + A*np.exp(-E*(x-(dtsums[0]+1 + dtsums[1]+1 + dtsums[2]+1)))+B*np.exp(-Ep*(dtsums[3]-x+dtsums[0]+1 + dtsums[1]+1 + dtsums[2]+1))
    var, Cov = curve_fit(fit, time_mask, newt[k,:],  p0 = [0,0,0], sigma = newsig, absolute_sigma = True, maxfev = 5000)
    hT.append(-var[0]*L*MD*hp/np.pi)
    wtab.append(w)
    
os.chdir('/Users/melissafaur/Desktop/Data_analysis/Results')

print('hT avg for mom2 :', np.array(hT).mean(), np.array(hT).std())

np.savetxt('{name}-{mass}-{mom}'.format(name=file, mass=mass_in, mom=2), (hT, wtab, Mpitab, np.sqrt(2*MKtab**2 - Mpitab**2)))

#We repeat the procedure for momentum norm "3"

hT = []

wtab = []

file_ED = input('name of the file where we find the energy for D meson (mom3) : ')

os.chdir('/Users/melissafaur/Desktop/mom1/Bootstrap')

tab = np.loadtxt(file_ED)
deltaED = tab[1:,9]-tab[1:,7]

os.chdir('/Users/melissafaur/Desktop/mom1/mom3_avg123-4/chi2_{mass}'.format(mass=mass_in))


tab = np.loadtxt('samples_total')
sig = np.loadtxt('sample_sigma')

newt = []
newsig = []
for k in range(5000):
    newt.append(list(tab[k,time_mask]))
newsig = sig[time_mask]
tab.shape

newt = np.array(newt)
newsig = np.array(newsig)

for k in tqdm(range(5000)):
    E = deltaED[k]
    Ep = deltaEB[k]
    MB = MBtab[k]
    MD = MDtab[k]
    hp = hptab[k]
    mom = np.sqrt(3)*2*np.pi/L
    q2 = (MB - np.sqrt(MD**2 + mom**2))**2 - mom**2
    w = (MB**2 + MD**2 - q2)/(2*MD*MB) #book HQphysics page 66
    @np.vectorize
    def fit(x, R,A,B):
        if x in list(np.arange(dtsums[0]+1)[cut: -cut]):
            return R + A*np.exp(-E*x)+B*np.exp(-Ep*(dtsums[0]-x))
        elif x in list(np.arange(dtsums[1]+1)[cut: -cut] + dtsums[0]+1):
            return R + A*np.exp(-E*(x-(dtsums[0]+1)))+B*np.exp(-Ep*(dtsums[1]-x + dtsums[0]+1))
        elif x in list(np.arange(dtsums[2]+1)[cut: -cut] + dtsums[0]+1 + dtsums[1]+1):
            return R + A*np.exp(-Ep*(x-(dtsums[0]+1 + dtsums[1]+1)))+B*np.exp(-Ep*(dtsums[2]-x + dtsums[0]+1 + dtsums[1]+1))
        else:
            return R + A*np.exp(-E*(x-(dtsums[0]+1 + dtsums[1]+1 + dtsums[2]+1)))+B*np.exp(-Ep*(dtsums[3]-x+dtsums[0]+1 + dtsums[1]+1 + dtsums[2]+1))
    var, Cov = curve_fit(fit, time_mask, newt[k,:],  p0 = [0,0,0], sigma = newsig, absolute_sigma = True, maxfev = 5000)
    hT.append(-var[0]*L*MD*hp/np.pi)
    wtab.append(w)

os.chdir('/Users/melissafaur/Desktop/Data_analysis/Results')

print('hT avg for mom3 :', np.array(hT).mean(), np.array(hT).std())

np.savetxt('{name}-{mass}-{mom}'.format(name=file, mass=mass_in, mom=3), (hT, wtab, Mpitab, np.sqrt(2*MKtab**2 - Mpitab**2)))

file_ED = input('name of the file where we find the energy for D meson (mom5) : ')

#We repeat the procedure for momentum norm "4"

hT =[]

wtab = []

os.chdir('/Users/melissafaur/Desktop/mom1/Bootstrap')

tab = np.loadtxt(file_ED)
deltaED = tab[1:,9]-tab[1:,7]

os.chdir('/Users/melissafaur/Desktop/mom1/mom4_avg123-4/chi2_{mass}'.format(mass=mass_in))


tab = np.loadtxt('samples_total')
sig = np.loadtxt('sample_sigma')

newt = []
newsig = []
for k in range(5000):
    newt.append(list(tab[k,time_mask]))
newsig = sig[time_mask]
tab.shape

newt = np.array(newt)
newsig = np.array(newsig)

for k in tqdm(range(5000)):
    E = deltaED[k]
    Ep = deltaEB[k]
    MB = MBtab[k]
    MD =  MDtab[k]
    hp = hptab[k]
    mom = 2*2*np.pi/L
    q2 = (MB - np.sqrt(MD**2 + mom**2))**2 - mom**2
    w = (MB**2 + MD**2 - q2)/(2*MD*MB) #book HQphysics page 66
    @np.vectorize
    def fit(x, R,A,B):
        if x in list(np.arange(dtsums[0]+1)[cut: -cut]):
            return R + A*np.exp(-E*x)+B*np.exp(-Ep*(dtsums[0]-x))
        elif x in list(np.arange(dtsums[1]+1)[cut: -cut] + dtsums[0]+1):
            return R + A*np.exp(-E*(x-(dtsums[0]+1)))+B*np.exp(-Ep*(dtsums[1]-x + dtsums[0]+1))
        elif x in list(np.arange(dtsums[2]+1)[cut: -cut] + dtsums[0]+1 + dtsums[1]+1):
            return R + A*np.exp(-Ep*(x-(dtsums[0]+1 + dtsums[1]+1)))+B*np.exp(-Ep*(dtsums[2]-x + dtsums[0]+1 + dtsums[1]+1))
        else:
            return R + A*np.exp(-E*(x-(dtsums[0]+1 + dtsums[1]+1 + dtsums[2]+1)))+B*np.exp(-Ep*(dtsums[3]-x+dtsums[0]+1 + dtsums[1]+1 + dtsums[2]+1))
    var, Cov = curve_fit(fit, time_mask, newt[k,:],  p0 = [0,0,0], sigma = newsig, absolute_sigma = True, maxfev = 5000)
    hT.append(-var[0]*L*MD*hp/(np.pi*2))
    wtab.append(w)

os.chdir('/Users/melissafaur/Desktop/Data_analysis/Results')

print('hT avg for mom4 :', np.array(hT).mean(), np.array(hT).std())

np.savetxt('{name}-{mass}-{mom}'.format(name=file, mass=mass_in, mom=4), (hT, wtab, Mpitab, np.sqrt(2*MKtab**2 - Mpitab**2)))

print('files saved under format : 4 lines * 5000 rows, 1 : hT, 2: w, 3: Mpi, 4: Metas')

os.system('umount -f /Users/melissafaur/Desktop/mom1')
